{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from data import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGenerator(batch_size,train_path,image_folder,mask_folder,aug_dict=data_gen_args,image_color_mode = \"rgb\",\n",
    "                    mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n",
    "                    flag_multi_class = False,num_class = 2,save_to_dir = None,\n",
    "                   target_size = (256,256),seed = 1):\n",
    "    '''\n",
    "    can generate image and mask at the same time\n",
    "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
    "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
    "    '''\n",
    "    image_datagen = ImageDataGenerator(**aug_dict, validation_split=0.2, rescale=1./255)\n",
    "    mask_datagen = ImageDataGenerator(**aug_dict, validation_split=0.2, rescale=1./255)\n",
    "    \n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = image_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = image_save_prefix,\n",
    "        subset = 'training',\n",
    "        seed = seed) \n",
    "    image_val_generator = image_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = image_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = image_save_prefix,\n",
    "        subset = 'validation',\n",
    "        seed = seed)\n",
    "    \n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = mask_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = mask_save_prefix,\n",
    "        subset = 'training',\n",
    "        seed = seed)\n",
    "    mask_val_generator = mask_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = mask_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = mask_save_prefix,\n",
    "        subset = 'validation',\n",
    "        seed = seed)\n",
    "    \n",
    "        \n",
    "    return image_generator, image_val_generator, mask_generator, mask_val_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 images belonging to 1 classes.\n",
      "Found 5 images belonging to 1 classes.\n",
      "Found 22 images belonging to 1 classes.\n",
      "Found 5 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "image_generator, image_val_generator, mask_generator, mask_val_generator = trainGenerator(3,'dataset','images_satellite','labels_satellite',data_gen_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(image_generator, mask_generator, flag_multi_class = False, num_class = 2):\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    for (img,mask) in train_generator:\n",
    "        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
    "        yield (img,mask)\n",
    "        \n",
    "def val(image_val_generator, mask_val_generator, flag_multi_class = False, num_class = 2):\n",
    "    val_generator = zip(image_val_generator, mask_val_generator)\n",
    "    for (img_val,mask_val) in val_generator:\n",
    "        img_val,mask_val = adjustData(img_val,mask_val,flag_multi_class,num_class)       \n",
    "        yield (img_val,mask_val)\n",
    "        \n",
    "train_generator = train(image_generator, mask_generator)\n",
    "val_generator = val(image_val_generator, mask_val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = satellite_unet()\n",
    "model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy', mean_iou])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4588 - accuracy: 0.6859 - mean_iou: 0.4391\n",
      "Epoch 00001: val_mean_iou improved from -inf to 0.55181, saving model to sat_unet_custom.hdf5\n",
      "100/100 [==============================] - 17s 172ms/step - loss: 0.4588 - accuracy: 0.6859 - mean_iou: 0.4391 - val_loss: 0.3326 - val_accuracy: 0.7564 - val_mean_iou: 0.5518\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3767 - accuracy: 0.7400 - mean_iou: 0.4933\n",
      "Epoch 00002: val_mean_iou improved from 0.55181 to 0.59461, saving model to sat_unet_custom.hdf5\n",
      "100/100 [==============================] - 16s 164ms/step - loss: 0.3767 - accuracy: 0.7400 - mean_iou: 0.4933 - val_loss: 0.3248 - val_accuracy: 0.7661 - val_mean_iou: 0.5946\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3519 - accuracy: 0.7452 - mean_iou: 0.5220\n",
      "Epoch 00003: val_mean_iou did not improve from 0.59461\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 0.3519 - accuracy: 0.7452 - mean_iou: 0.5220 - val_loss: 0.3201 - val_accuracy: 0.7574 - val_mean_iou: 0.5562\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3164 - accuracy: 0.7618 - mean_iou: 0.5673\n",
      "Epoch 00004: val_mean_iou did not improve from 0.59461\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 0.3164 - accuracy: 0.7618 - mean_iou: 0.5673 - val_loss: 0.3280 - val_accuracy: 0.7577 - val_mean_iou: 0.5717\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.3147 - accuracy: 0.7634 - mean_iou: 0.5801\n",
      "Epoch 00005: val_mean_iou improved from 0.59461 to 0.61162, saving model to sat_unet_custom.hdf5\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.3147 - accuracy: 0.7634 - mean_iou: 0.5801 - val_loss: 0.3480 - val_accuracy: 0.7597 - val_mean_iou: 0.6116\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2879 - accuracy: 0.7748 - mean_iou: 0.6194\n",
      "Epoch 00006: val_mean_iou did not improve from 0.61162\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 0.2879 - accuracy: 0.7748 - mean_iou: 0.6194 - val_loss: 0.3244 - val_accuracy: 0.7656 - val_mean_iou: 0.5494\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2757 - accuracy: 0.7779 - mean_iou: 0.6243\n",
      "Epoch 00007: val_mean_iou did not improve from 0.61162\n",
      "100/100 [==============================] - 16s 161ms/step - loss: 0.2757 - accuracy: 0.7779 - mean_iou: 0.6243 - val_loss: 0.3183 - val_accuracy: 0.7641 - val_mean_iou: 0.5961\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2680 - accuracy: 0.7833 - mean_iou: 0.6429\n",
      "Epoch 00008: val_mean_iou did not improve from 0.61162\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 0.2680 - accuracy: 0.7833 - mean_iou: 0.6429 - val_loss: 0.4309 - val_accuracy: 0.7337 - val_mean_iou: 0.5615\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2520 - accuracy: 0.7883 - mean_iou: 0.6679\n",
      "Epoch 00009: val_mean_iou did not improve from 0.61162\n",
      "100/100 [==============================] - 16s 158ms/step - loss: 0.2520 - accuracy: 0.7883 - mean_iou: 0.6679 - val_loss: 0.3532 - val_accuracy: 0.7569 - val_mean_iou: 0.5554\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2462 - accuracy: 0.7921 - mean_iou: 0.6747\n",
      "Epoch 00010: val_mean_iou did not improve from 0.61162\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 0.2462 - accuracy: 0.7921 - mean_iou: 0.6747 - val_loss: 0.4315 - val_accuracy: 0.7548 - val_mean_iou: 0.5985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f68e0e30ad0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint = ModelCheckpoint('sat_unet_custom.hdf5', monitor='val_mean_iou',verbose=1, save_best_only=True, mode = 'max')\n",
    "model.fit_generator(train_generator,steps_per_epoch=100,epochs=10,validation_data=val_generator,validation_steps=50, callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 256, 256, 3)\n",
      "(4, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "test_img, _= test('dataset/test_images')\n",
    "print(test_img.shape)\n",
    "\n",
    "folder = './dataset/test_labels'\n",
    "num_img, size = test_img.shape[0], test_img.shape[1]\n",
    "\n",
    "test_label = generate_labels(folder, num_img, size, False)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2346 - accuracy: 0.7664 - mean_iou: 0.1393\n",
      "Test score: 1.2346317768096924\n"
     ]
    }
   ],
   "source": [
    "model = load_model('sat_unet_custom.hdf5', compile = False)\n",
    "model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy', mean_iou])\n",
    "\n",
    "score, accuracy, mean_iou= model.evaluate(test_img, test_label)\n",
    "print('Test score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "X_test,names=test(\"dataset/test_images\")\n",
    "names = [\"custom\" + name for name in names]\n",
    "preds=model.predict(X_test)\n",
    "preds=preds>0.5\n",
    "results=predToImgs(preds)\n",
    "saveResults(os.getcwd()+\"/dataset/test_labels\",results,names,empty_dir=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score IoU: 0.627258658\n",
      "Test score dice coefficient: 0.758369446\n"
     ]
    }
   ],
   "source": [
    "predict_label = generate_labels(\"./dataset/test_labels\", num_img, size, True )\n",
    "tf_test = tf.convert_to_tensor(test_label[:, :, :, :], dtype = 'float32')\n",
    "tf_predict = tf.convert_to_tensor(predict_label[:, :, :, :], dtype = 'float32')\n",
    "\n",
    "result_iou = mean_iou_neg(tf_test, tf_predict)\n",
    "tf.print('Test score IoU:',result_iou)\n",
    "\n",
    "result_dice = dice(tf_test, tf_predict)\n",
    "tf.print('Test score dice coefficient:',result_dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "metadata": {
   "deletable": true,
   "editable": true,
   "trusted": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
