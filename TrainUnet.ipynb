{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from data import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train form data in dataset using data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 images belonging to 1 classes.\n",
      "Found 5 images belonging to 1 classes.\n",
      "Found 22 images belonging to 1 classes.\n",
      "Found 5 images belonging to 1 classes.\n",
      "WARNING:tensorflow:From <ipython-input-5-ad2b357304cb>:12: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 800 steps, validate for 120 steps\n",
      "Epoch 1/5\n",
      "799/800 [============================>.] - ETA: 0s - loss: 0.3087 - accuracy: 0.7734 - mean_io_u: 0.3872WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "800/800 [==============================] - 118s 147ms/step - loss: 0.3086 - accuracy: 0.7735 - mean_io_u: 0.3872 - val_loss: 2.4169 - val_accuracy: 0.3749 - val_mean_io_u: 0.3397\n",
      "Epoch 2/5\n",
      "799/800 [============================>.] - ETA: 0s - loss: 0.2136 - accuracy: 0.8109 - mean_io_u: 0.3872WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "800/800 [==============================] - 106s 133ms/step - loss: 0.2135 - accuracy: 0.8110 - mean_io_u: 0.3872 - val_loss: 0.8601 - val_accuracy: 0.5874 - val_mean_io_u: 0.3405\n",
      "Epoch 3/5\n",
      "799/800 [============================>.] - ETA: 0s - loss: 0.1625 - accuracy: 0.8261 - mean_io_u: 0.3870WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "800/800 [==============================] - 107s 133ms/step - loss: 0.1623 - accuracy: 0.8261 - mean_io_u: 0.3871 - val_loss: 0.9847 - val_accuracy: 0.5671 - val_mean_io_u: 0.3404\n",
      "Epoch 4/5\n",
      "799/800 [============================>.] - ETA: 0s - loss: 0.1339 - accuracy: 0.8337 - mean_io_u: 0.3871WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "800/800 [==============================] - 107s 134ms/step - loss: 0.1337 - accuracy: 0.8337 - mean_io_u: 0.3872 - val_loss: 1.0250 - val_accuracy: 0.5873 - val_mean_io_u: 0.3406\n",
      "Epoch 5/5\n",
      "799/800 [============================>.] - ETA: 0s - loss: 0.1132 - accuracy: 0.8380 - mean_io_u: 0.3870WARNING:tensorflow:Can save best model only with acc available, skipping.\n",
      "800/800 [==============================] - 108s 135ms/step - loss: 0.1132 - accuracy: 0.8380 - mean_io_u: 0.3870 - val_loss: 0.7337 - val_accuracy: 0.6110 - val_mean_io_u: 0.3402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbd6d284310>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    vertical_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "myGene = trainGenerator(3,'dataset','images','labels',data_gen_args,save_to_dir = None)\n",
    "model = satellite_unet()\n",
    "model_checkpoint = ModelCheckpoint('sat_unet.hdf5', monitor='acc',verbose=1, save_best_only=True)\n",
    "model.fit_generator(train_generator,steps_per_epoch=800,epochs=5,validation_data=val_generator,validation_steps=120, callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=satellite_unet(pretrained='sat_unet.hdf5')\n",
    "X_test,names=test(\"dataset/unlabelled\")\n",
    "preds=model.predict(X_test)\n",
    "preds=preds>0.5\n",
    "results=predToImgs(preds)\n",
    "saveResults(\"dataset/preds\",results,names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 256, 256, 3)\n",
      "(14, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "def test(test_path,target_size=(256,256), color_mode = \"rgb\"):\n",
    "    X_test=[]\n",
    "    names=[]\n",
    "    for filename in os.listdir(test_path):\n",
    "        name, ext = os.path.splitext(filename)\n",
    "        if ext!=\".png\" and ext!=\".jpg\":\n",
    "            continue\n",
    "        names.append(filename)\n",
    "        img=load_img(os.path.join(test_path,filename),target_size=(256,256), color_mode = color_mode)\n",
    "        img=img_to_array(img)/255\n",
    "        X_test.append(img.copy())\n",
    "    X_test_label = np.array(X_test)\n",
    "    return X_test_label\n",
    "\n",
    "test_img = test('dataset/images_satelite')\n",
    "# test_img = test_img[1:,:,:,:]\n",
    "print(test_img.shape)\n",
    "\n",
    "test_label = test('dataset/labels_satelite', color_mode = \"grayscale\")\n",
    "print(test_label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 52ms/sample - loss: 1.5818 - accuracy: 0.6035\n",
      "Test score: 1.581809163093567\n",
      "Test accuracy: 0.6035216\n"
     ]
    }
   ],
   "source": [
    "model=satellite_unet(pretrained='sat_unet.hdf5')\n",
    "\n",
    "score, acc = model.evaluate(test_img, test_label)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    vertical_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "myGene = trainGenerator(3,'dataset','images','labels',data_gen_args,save_to_dir = None)\n",
    "model = satellite_unet()\n",
    "model_checkpoint = ModelCheckpoint('sat_unet_IoU.hdf5', monitor='acc',verbose=1, save_best_only=False)\n",
    "model.fit_generator(myGene,steps_per_epoch=2000,epochs=5,callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 60ms/sample - loss: 1.9629 - mean_io_u_1: 0.4234\n",
      "Test score: 1.9629113674163818\n",
      "Test accuracy: 0.4234361\n"
     ]
    }
   ],
   "source": [
    "model=satellite_unet(pretrained='sat_unet_IoU.hdf5')\n",
    "\n",
    "score, acc = model.evaluate(test_img, test_label)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tried data from the same distribution, split data from our satelite images into train and validation sets\n",
    "\n",
    "def trainGenerator(batch_size,train_path,image_folder,mask_folder,aug_dict=data_gen_args,image_color_mode = \"rgb\",\n",
    "                    mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n",
    "                    flag_multi_class = False,num_class = 2,save_to_dir = None,\n",
    "                   target_size = (256,256),seed = 1):\n",
    "    '''\n",
    "    can generate image and mask at the same time\n",
    "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
    "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
    "    '''\n",
    "    image_datagen = ImageDataGenerator(**aug_dict, validation_split=0.2, rescale=1./255)\n",
    "    mask_datagen = ImageDataGenerator(**aug_dict, validation_split=0.2, rescale=1./255)\n",
    "    \n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = image_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = image_save_prefix,\n",
    "        subset = 'training',\n",
    "        seed = seed) \n",
    "    image_val_generator = image_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = image_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = image_save_prefix,\n",
    "        subset = 'validation',\n",
    "        seed = seed)\n",
    "    \n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = mask_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = mask_save_prefix,\n",
    "        subset = 'training',\n",
    "        seed = seed)\n",
    "    mask_val_generator = mask_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = mask_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = mask_save_prefix,\n",
    "        subset = 'validation',\n",
    "        seed = seed)\n",
    "    \n",
    "        \n",
    "    return image_generator, image_val_generator, mask_generator, mask_val_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 images belonging to 1 classes.\n",
      "Found 5 images belonging to 1 classes.\n",
      "Found 22 images belonging to 1 classes.\n",
      "Found 5 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "image_generator, image_val_generator, mask_generator, mask_val_generator = trainGenerator(3,'dataset','images','labels',data_gen_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(image_generator, mask_generator, flag_multi_class = False, num_class = 2):\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    for (img,mask) in train_generator:\n",
    "        img,mask = adjustData(img,mask,flag_multi_class,num_class)       \n",
    "        yield (img,mask)\n",
    "        \n",
    "def val(image_val_generator, mask_val_generator, flag_multi_class = False, num_class = 2):\n",
    "    val_generator = zip(image_val_generator, mask_val_generator)\n",
    "    for (img_val,mask_val) in val_generator:\n",
    "        img_val,mask_val = adjustData(img_val,mask_val,flag_multi_class,num_class)       \n",
    "        yield (img_val,mask_val)\n",
    "        \n",
    "train_generator = train(image_generator, mask_generator)\n",
    "val_generator = val(image_val_generator, mask_val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-00de7c070fb5>:3: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 800 steps, validate for 120 steps\n",
      "Epoch 1/15\n",
      "799/800 [============================>.] - ETA: 0s - loss: 0.1776 - accuracy: 0.8718 - mean_io_u: 0.4091\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.68679, saving model to sat_unet_new.hdf5\n",
      "800/800 [==============================] - 161s 201ms/step - loss: 0.1775 - accuracy: 0.8718 - mean_io_u: 0.4092 - val_loss: 1.7942 - val_accuracy: 0.6868 - val_mean_io_u: 0.4710\n",
      "Epoch 2/15\n",
      "799/800 [============================>.] - ETA: 0s - loss: 0.0695 - accuracy: 0.9100 - mean_io_u: 0.4140\n",
      "Epoch 00002: val_accuracy improved from 0.68679 to 0.71726, saving model to sat_unet_new.hdf5\n",
      "800/800 [==============================] - 150s 187ms/step - loss: 0.0694 - accuracy: 0.9101 - mean_io_u: 0.4141 - val_loss: 1.4540 - val_accuracy: 0.7173 - val_mean_io_u: 0.5707\n",
      "Epoch 3/15\n",
      "799/800 [============================>.] - ETA: 0s - loss: 0.0514 - accuracy: 0.9135 - mean_io_u: 0.4165\n",
      "Epoch 00003: val_accuracy improved from 0.71726 to 0.77259, saving model to sat_unet_new.hdf5\n",
      "800/800 [==============================] - 150s 188ms/step - loss: 0.0514 - accuracy: 0.9135 - mean_io_u: 0.4165 - val_loss: 1.3683 - val_accuracy: 0.7726 - val_mean_io_u: 0.5108\n",
      "Epoch 4/15\n",
      "799/800 [============================>.] - ETA: 0s - loss: 0.0432 - accuracy: 0.9148 - mean_io_u: 0.4160\n",
      "Epoch 00004: val_accuracy did not improve from 0.77259\n",
      "800/800 [==============================] - 149s 187ms/step - loss: 0.0432 - accuracy: 0.9148 - mean_io_u: 0.4160 - val_loss: 1.7525 - val_accuracy: 0.7148 - val_mean_io_u: 0.4922\n",
      "Epoch 5/15\n",
      "799/800 [============================>.] - ETA: 0s - loss: 0.0484 - accuracy: 0.9135 - mean_io_u: 0.4092\n",
      "Epoch 00005: val_accuracy did not improve from 0.77259\n",
      "800/800 [==============================] - 150s 187ms/step - loss: 0.0484 - accuracy: 0.9135 - mean_io_u: 0.4093 - val_loss: 1.0361 - val_accuracy: 0.7385 - val_mean_io_u: 0.4507\n",
      "Epoch 6/15\n",
      "799/800 [============================>.] - ETA: 0s - loss: 0.0369 - accuracy: 0.9155 - mean_io_u: 0.4092\n",
      "Epoch 00006: val_accuracy did not improve from 0.77259\n",
      "800/800 [==============================] - 150s 187ms/step - loss: 0.0369 - accuracy: 0.9155 - mean_io_u: 0.4092 - val_loss: 1.2066 - val_accuracy: 0.7537 - val_mean_io_u: 0.4822\n",
      "Epoch 7/15\n",
      "799/800 [============================>.] - ETA: 0s - loss: 0.0410 - accuracy: 0.9146 - mean_io_u: 0.4090\n",
      "Epoch 00007: val_accuracy did not improve from 0.77259\n",
      "800/800 [==============================] - 150s 188ms/step - loss: 0.0411 - accuracy: 0.9145 - mean_io_u: 0.4088 - val_loss: 1.0283 - val_accuracy: 0.7557 - val_mean_io_u: 0.4481\n",
      "Epoch 8/15\n",
      "799/800 [============================>.] - ETA: 0s - loss: 0.0293 - accuracy: 0.9165 - mean_io_u: 0.4090\n",
      "Epoch 00008: val_accuracy did not improve from 0.77259\n",
      "800/800 [==============================] - 149s 187ms/step - loss: 0.0293 - accuracy: 0.9164 - mean_io_u: 0.4089 - val_loss: 1.1604 - val_accuracy: 0.7032 - val_mean_io_u: 0.4485\n",
      "Epoch 9/15\n",
      "799/800 [============================>.] - ETA: 0s - loss: 0.0346 - accuracy: 0.9154 - mean_io_u: 0.4086\n",
      "Epoch 00009: val_accuracy improved from 0.77259 to 0.79127, saving model to sat_unet_new.hdf5\n",
      "800/800 [==============================] - 150s 187ms/step - loss: 0.0346 - accuracy: 0.9154 - mean_io_u: 0.4086 - val_loss: 0.6741 - val_accuracy: 0.7913 - val_mean_io_u: 0.4548\n",
      "Epoch 10/15\n",
      "799/800 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9157 - mean_io_u: 0.4085\n",
      "Epoch 00010: val_accuracy improved from 0.79127 to 0.80364, saving model to sat_unet_new.hdf5\n",
      "800/800 [==============================] - 149s 186ms/step - loss: 0.0315 - accuracy: 0.9157 - mean_io_u: 0.4085 - val_loss: 0.5441 - val_accuracy: 0.8036 - val_mean_io_u: 0.4477\n",
      "Epoch 11/15\n",
      "799/800 [============================>.] - ETA: 0s - loss: 0.0281 - accuracy: 0.9162 - mean_io_u: 0.4086\n",
      "Epoch 00011: val_accuracy did not improve from 0.80364\n",
      "800/800 [==============================] - 147s 183ms/step - loss: 0.0281 - accuracy: 0.9161 - mean_io_u: 0.4085 - val_loss: 0.8878 - val_accuracy: 0.7719 - val_mean_io_u: 0.4481\n",
      "Epoch 12/15\n",
      "799/800 [============================>.] - ETA: 0s - loss: 0.0237 - accuracy: 0.9168 - mean_io_u: 0.4085\n",
      "Epoch 00012: val_accuracy did not improve from 0.80364\n",
      "800/800 [==============================] - 148s 185ms/step - loss: 0.0237 - accuracy: 0.9169 - mean_io_u: 0.4085 - val_loss: 0.9054 - val_accuracy: 0.7664 - val_mean_io_u: 0.4509\n",
      "Epoch 13/15\n",
      "799/800 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9169 - mean_io_u: 0.4085\n",
      "Epoch 00013: val_accuracy did not improve from 0.80364\n",
      "800/800 [==============================] - 150s 188ms/step - loss: 0.0212 - accuracy: 0.9169 - mean_io_u: 0.4085 - val_loss: 1.1700 - val_accuracy: 0.7217 - val_mean_io_u: 0.4484\n",
      "Epoch 14/15\n",
      "799/800 [============================>.] - ETA: 0s - loss: 0.0316 - accuracy: 0.9151 - mean_io_u: 0.4084\n",
      "Epoch 00014: val_accuracy did not improve from 0.80364\n",
      "800/800 [==============================] - 148s 185ms/step - loss: 0.0316 - accuracy: 0.9151 - mean_io_u: 0.4085 - val_loss: 0.8585 - val_accuracy: 0.7558 - val_mean_io_u: 0.4806\n",
      "Epoch 15/15\n",
      "799/800 [============================>.] - ETA: 0s - loss: 0.0239 - accuracy: 0.9167 - mean_io_u: 0.4087\n",
      "Epoch 00015: val_accuracy did not improve from 0.80364\n",
      "800/800 [==============================] - 148s 185ms/step - loss: 0.0239 - accuracy: 0.9166 - mean_io_u: 0.4087 - val_loss: 0.6293 - val_accuracy: 0.7992 - val_mean_io_u: 0.4488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f80907a3750>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = satellite_unet()\n",
    "model_checkpoint = ModelCheckpoint('sat_unet_new.hdf5', monitor='val_accuracy',verbose=1, save_best_only=True)\n",
    "model.fit_generator(train_generator,steps_per_epoch=800,epochs=15,validation_data=val_generator,validation_steps=120, callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 658ms/sample - loss: 0.5112 - accuracy: 0.8522 - mean_io_u: 0.4948\n",
      "Test score: [0.5111860036849976, 0.8522415, 0.49476242]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9990ea038e59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# print('Test IoU:', Iou)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'acc' is not defined"
     ]
    }
   ],
   "source": [
    "test_img = test('dataset/test_images')\n",
    "test_label = test('dataset/test_labels', color_mode = \"grayscale\")\n",
    "model=satellite_unet(pretrained='sat_unet_new.hdf5')\n",
    "\n",
    "score= model.evaluate(test_img, test_label)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "# print('Test IoU:', Iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test2(test_path,target_size=(256,256)):\n",
    "    X_test=[]\n",
    "    names=[]\n",
    "    for filename in os.listdir(test_path):\n",
    "        name, ext = os.path.splitext(filename)\n",
    "        if ext!=\".png\" and ext!=\".jpg\":\n",
    "            continue\n",
    "        names.append(filename)\n",
    "        img=load_img(os.path.join(test_path,filename),target_size=target_size)\n",
    "        img=img_to_array(img)/255\n",
    "        X_test.append(img.copy())\n",
    "    return np.array(X_test),names\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/home/RemyZ/cs231n-project/dataset/generator_images/IMG-21_predict.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4d297006d068>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredToImgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msaveResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/dataset/generator_images\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mempty_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/RemyZ/cs231n-project/data.py\u001b[0m in \u001b[0;36msaveResults\u001b[0;34m(save_path, results, names, empty_dir)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marray_to_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mappend_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_remove_readonly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexcinfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2129\u001b[0m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2131\u001b[0;31m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2133\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/home/RemyZ/cs231n-project/dataset/generator_images/IMG-21_predict.png'"
     ]
    }
   ],
   "source": [
    "### TO DO ####\n",
    "import os\n",
    "\n",
    "model=satellite_unet(pretrained='sat_unet_new.hdf5')\n",
    "X_test,names=test2(\"dataset/images\")\n",
    "preds=model.predict(X_test)\n",
    "preds=preds>0.5\n",
    "results=predToImgs(preds)\n",
    "saveResults(os.getcwd()+\"/dataset/generator_images\",results,names,empty_dir=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "metadata": {
   "deletable": true,
   "editable": true,
   "trusted": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
