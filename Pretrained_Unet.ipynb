{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n"
     ]
    }
   ],
   "source": [
    "from model import *\n",
    "from data import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "import segmentation_models as sm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'resnet34' #Pretrained backbone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train form data in dataset using data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet34_imagenet_1000_no_top.h5\n",
      "85524480/85521592 [==============================] - 4s 0us/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-749f69d57dab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbce_jaccard_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pretrained_unet.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    vertical_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "myGene = trainGenerator(3,'dataset','images','labels',data_gen_args,save_to_dir = None)\n",
    "model = sm.Unet(BACKBONE)\n",
    "model.compile('Adam',loss=sm.losses.bce_jaccard_loss,metrics=['acc'])\n",
    "model_checkpoint = ModelCheckpoint('pretrained_unet.hdf5', monitor='acc',verbose=1, save_best_only=True)\n",
    "model.fit_generator(train_generator,steps_per_epoch=800,epochs=5,validation_data=val_generator,validation_steps=120, callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=satellite_unet(pretrained='sat_unet.hdf5')\n",
    "X_test,names=test(\"dataset/unlabelled\")\n",
    "preds=model.predict(X_test)\n",
    "preds=preds>0.5\n",
    "results=predToImgs(preds)\n",
    "saveResults(\"dataset/preds\",results,names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 256, 256, 3)\n",
      "(14, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "def test(test_path,target_size=(256,256), color_mode = \"rgb\"):\n",
    "    X_test=[]\n",
    "    names=[]\n",
    "    for filename in os.listdir(test_path):\n",
    "        name, ext = os.path.splitext(filename)\n",
    "        if ext!=\".png\" and ext!=\".jpg\":\n",
    "            continue\n",
    "        names.append(filename)\n",
    "        img=load_img(os.path.join(test_path,filename),target_size=(256,256), color_mode = color_mode)\n",
    "        img=img_to_array(img)/255\n",
    "        X_test.append(img.copy())\n",
    "    X_test_label = np.array(X_test)\n",
    "    return X_test_label\n",
    "\n",
    "test_img = test('dataset/images_satelite')\n",
    "# test_img = test_img[1:,:,:,:]\n",
    "print(test_img.shape)\n",
    "\n",
    "test_label = test('dataset/labels_satelite', color_mode = \"grayscale\")\n",
    "print(test_label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 52ms/sample - loss: 1.5818 - accuracy: 0.6035\n",
      "Test score: 1.581809163093567\n",
      "Test accuracy: 0.6035216\n"
     ]
    }
   ],
   "source": [
    "model=satellite_unet(pretrained='sat_unet.hdf5')\n",
    "\n",
    "score, acc = model.evaluate(test_img, test_label)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_args = dict(rotation_range=0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    vertical_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "myGene = trainGenerator(3,'dataset','images','labels',data_gen_args,save_to_dir = None)\n",
    "model = sm.Unet(BACKBONE)\n",
    "model.compile(tf.keras.optimizers.Adam(1e-4),loss=sm.losses.bce_jaccard_loss,metrics=['acc'])\n",
    "model_checkpoint = ModelCheckpoint('pretrained_unet.hdf5', monitor='acc',verbose=1, save_best_only=True)\n",
    "model.fit_generator(myGene,steps_per_epoch=2000,epochs=5,callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 60ms/sample - loss: 1.9629 - mean_io_u_1: 0.4234\n",
      "Test score: 1.9629113674163818\n",
      "Test accuracy: 0.4234361\n"
     ]
    }
   ],
   "source": [
    "model=satellite_unet(pretrained='sat_unet_IoU.hdf5')\n",
    "\n",
    "score, acc = model.evaluate(test_img, test_label)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tried data from the same distribution, split data from our satelite images into train and validation sets\n",
    "\n",
    "def trainGenerator(batch_size,train_path,image_folder,mask_folder,aug_dict=data_gen_args,image_color_mode = \"rgb\",\n",
    "                    mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n",
    "                    flag_multi_class = False,num_class = 2,save_to_dir = None,\n",
    "                   target_size = (256,256),seed = 1):\n",
    "    '''\n",
    "    can generate image and mask at the same time\n",
    "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
    "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
    "    '''\n",
    "    image_datagen = ImageDataGenerator(**aug_dict, validation_split=0.2, rescale=1./255)\n",
    "    mask_datagen = ImageDataGenerator(**aug_dict, validation_split=0.2, rescale=1./255)\n",
    "    \n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = image_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = image_save_prefix,\n",
    "        subset = 'training',\n",
    "        seed = seed) \n",
    "    image_val_generator = image_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = image_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = image_save_prefix,\n",
    "        subset = 'validation',\n",
    "        seed = seed)\n",
    "    \n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = mask_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = mask_save_prefix,\n",
    "        subset = 'training',\n",
    "        seed = seed)\n",
    "    mask_val_generator = mask_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = mask_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = mask_save_prefix,\n",
    "        subset = 'validation',\n",
    "        seed = seed)\n",
    "    \n",
    "        \n",
    "    return image_generator, image_val_generator, mask_generator, mask_val_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 images belonging to 1 classes.\n",
      "Found 2 images belonging to 1 classes.\n",
      "Found 12 images belonging to 1 classes.\n",
      "Found 2 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "image_generator, image_val_generator, mask_generator, mask_val_generator = trainGenerator(8,'dataset','images_satelite','labels_satelite',data_gen_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(image_generator, mask_generator, flag_multi_class = False, num_class = 2):\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    for (img,mask) in train_generator:\n",
    "        img,mask = adjustData(img,mask,flag_multi_class,num_class)       \n",
    "        yield (img,mask)\n",
    "        \n",
    "def val(image_val_generator, mask_val_generator, flag_multi_class = False, num_class = 2):\n",
    "    val_generator = zip(image_val_generator, mask_val_generator)\n",
    "    for (img_val,mask_val) in val_generator:\n",
    "        img_val,mask_val = adjustData(img_val,mask_val,flag_multi_class,num_class)       \n",
    "        yield (img_val,mask_val)\n",
    "        \n",
    "train_generator = train(image_generator, mask_generator)\n",
    "val_generator = val(image_val_generator, mask_val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1000 steps, validate for 100 steps\n",
      "Epoch 1/3\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.2531 - acc: 0.9038\n",
      "Epoch 00001: val_acc improved from -inf to 0.82981, saving model to pretrained_unet.hdf5\n",
      "1000/1000 [==============================] - 187s 187ms/step - loss: 0.2529 - acc: 0.9038 - val_loss: 1.0387 - val_acc: 0.8298\n",
      "Epoch 2/3\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.0873 - acc: 0.9164\n",
      "Epoch 00002: val_acc improved from 0.82981 to 0.84140, saving model to pretrained_unet.hdf5\n",
      "1000/1000 [==============================] - 181s 181ms/step - loss: 0.0872 - acc: 0.9164 - val_loss: 1.1597 - val_acc: 0.8414\n",
      "Epoch 3/3\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9169\n",
      "Epoch 00003: val_acc improved from 0.84140 to 0.85904, saving model to pretrained_unet.hdf5\n",
      "1000/1000 [==============================] - 180s 180ms/step - loss: 0.0662 - acc: 0.9169 - val_loss: 1.0523 - val_acc: 0.8590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff004ce7390>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.Unet(BACKBONE,encoder_weights='imagenet',input_shape=(256,256,3),encoder_freeze=True)\n",
    "model.compile(tf.keras.optimizers.Adam(),loss=sm.losses.bce_jaccard_loss,metrics=['acc'])\n",
    "model_checkpoint = ModelCheckpoint('pretrained_unet.hdf5', monitor='val_acc',verbose=1, save_best_only=True)\n",
    "model.fit_generator(train_generator,steps_per_epoch=1000,epochs=3,validation_data=val_generator,validation_steps=100, callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 500 steps, validate for 100 steps\n",
      "Epoch 1/10\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9173\n",
      "Epoch 00001: val_acc did not improve from 0.87073\n",
      "500/500 [==============================] - 99s 197ms/step - loss: 0.0427 - acc: 0.9173 - val_loss: 0.9836 - val_acc: 0.8654\n",
      "Epoch 2/10\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9173\n",
      "Epoch 00002: val_acc did not improve from 0.87073\n",
      "500/500 [==============================] - 94s 188ms/step - loss: 0.0451 - acc: 0.9173 - val_loss: 1.0076 - val_acc: 0.8636\n",
      "Epoch 3/10\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9165\n",
      "Epoch 00003: val_acc did not improve from 0.87073\n",
      "500/500 [==============================] - 94s 188ms/step - loss: 0.0534 - acc: 0.9165 - val_loss: 1.0208 - val_acc: 0.8616\n",
      "Epoch 4/10\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0528 - acc: 0.9166\n",
      "Epoch 00004: val_acc did not improve from 0.87073\n",
      "500/500 [==============================] - 94s 188ms/step - loss: 0.0528 - acc: 0.9167 - val_loss: 1.0277 - val_acc: 0.8609\n",
      "Epoch 5/10\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9165\n",
      "Epoch 00005: val_acc did not improve from 0.87073\n",
      "500/500 [==============================] - 94s 187ms/step - loss: 0.0549 - acc: 0.9165 - val_loss: 1.0317 - val_acc: 0.8602\n",
      "Epoch 6/10\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9166\n",
      "Epoch 00006: val_acc did not improve from 0.87073\n",
      "500/500 [==============================] - 94s 188ms/step - loss: 0.0529 - acc: 0.9167 - val_loss: 1.0267 - val_acc: 0.8617\n",
      "Epoch 7/10\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9164\n",
      "Epoch 00007: val_acc did not improve from 0.87073\n",
      "500/500 [==============================] - 94s 188ms/step - loss: 0.0555 - acc: 0.9163 - val_loss: 1.0232 - val_acc: 0.8612\n",
      "Epoch 8/10\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9164\n",
      "Epoch 00008: val_acc did not improve from 0.87073\n",
      "500/500 [==============================] - 95s 189ms/step - loss: 0.0574 - acc: 0.9164 - val_loss: 1.0368 - val_acc: 0.8603\n",
      "Epoch 9/10\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9164\n",
      "Epoch 00009: val_acc did not improve from 0.87073\n",
      "500/500 [==============================] - 95s 190ms/step - loss: 0.0584 - acc: 0.9163 - val_loss: 1.0393 - val_acc: 0.8603\n",
      "Epoch 10/10\n",
      "499/500 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9165\n",
      "Epoch 00010: val_acc did not improve from 0.87073\n",
      "500/500 [==============================] - 95s 190ms/step - loss: 0.0532 - acc: 0.9165 - val_loss: 1.0316 - val_acc: 0.8601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff02c201bd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "model.compile(tf.keras.optimizers.Adam(1e-6),loss=sm.losses.bce_jaccard_loss,metrics=['acc'])\n",
    "model.fit_generator(train_generator,steps_per_epoch=500,epochs=10,validation_data=val_generator,validation_steps=100, callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 198ms/sample - loss: 1.9746 - acc: 0.8629\n",
      "Test score: [1.9745510816574097, 0.86291885]\n"
     ]
    }
   ],
   "source": [
    "test_img = test('dataset/test_images')\n",
    "test_label = test('dataset/test_labels', color_mode = \"grayscale\")\n",
    "#model=satellite_unet(pretrained='pretrained_unet.hdf5')\n",
    "\n",
    "score= model.evaluate(test_img, test_label)\n",
    "print('Test score:', score)\n",
    "#print('Test accuracy:', acc)\n",
    "# print('Test IoU:', Iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test2(test_path,target_size=(256,256)):\n",
    "    X_test=[]\n",
    "    names=[]\n",
    "    for filename in os.listdir(test_path):\n",
    "        name, ext = os.path.splitext(filename)\n",
    "        if ext!=\".png\" and ext!=\".jpg\":\n",
    "            continue\n",
    "        names.append(filename)\n",
    "        img=load_img(os.path.join(test_path,filename),target_size=target_size)\n",
    "        img=img_to_array(img)/255\n",
    "        X_test.append(img.copy())\n",
    "    return np.array(X_test),names\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO ####\n",
    "import os\n",
    "\n",
    "#model=satellite_unet(pretrained='sat_unet_new.hdf5')\n",
    "X_test,names=test2(\"dataset/test_images\")\n",
    "preds=model.predict(X_test)\n",
    "preds=preds>0.5\n",
    "results=predToImgs(preds)\n",
    "saveResults(os.getcwd()+\"/dataset/generator_images\",results,names,empty_dir=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "metadata": {
   "deletable": true,
   "editable": true,
   "trusted": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
