{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from model import *\n",
    "from data import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint \n",
    "import segmentation_models as sm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'resnet34' #Pretrained backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tried data from the same distribution, split data from our satelite images into train and validation sets\n",
    "\n",
    "def trainGenerator(batch_size,train_path,image_folder,mask_folder,aug_dict=data_gen_args,image_color_mode = \"rgb\",\n",
    "                    mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n",
    "                    flag_multi_class = False,num_class = 2,save_to_dir = None,\n",
    "                   target_size = (256,256),seed = 1):\n",
    "    '''\n",
    "    can generate image and mask at the same time\n",
    "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
    "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
    "    '''\n",
    "    image_datagen = ImageDataGenerator(**aug_dict, validation_split=0.2, rescale=1./255)\n",
    "    mask_datagen = ImageDataGenerator(**aug_dict, validation_split=0.2, rescale=1./255)\n",
    "    \n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = image_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = image_save_prefix,\n",
    "        subset = 'training',\n",
    "        seed = seed) \n",
    "    image_val_generator = image_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = image_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = image_save_prefix,\n",
    "        subset = 'validation',\n",
    "        seed = seed)\n",
    "    \n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = mask_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = mask_save_prefix,\n",
    "        subset = 'training',\n",
    "        seed = seed)\n",
    "    mask_val_generator = mask_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = mask_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = mask_save_prefix,\n",
    "        subset = 'validation',\n",
    "        seed = seed)\n",
    "    \n",
    "        \n",
    "    return image_generator, image_val_generator, mask_generator, mask_val_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 images belonging to 1 classes.\n",
      "Found 5 images belonging to 1 classes.\n",
      "Found 22 images belonging to 1 classes.\n",
      "Found 5 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "image_generator, image_val_generator, mask_generator, mask_val_generator = trainGenerator(8,'dataset','images_satellite','labels_satellite',data_gen_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(image_generator, mask_generator, flag_multi_class = False, num_class = 2):\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    for (img,mask) in train_generator:\n",
    "        img,mask = adjustData(img,mask,flag_multi_class,num_class)       \n",
    "        yield (img,mask)\n",
    "        \n",
    "def val(image_val_generator, mask_val_generator, flag_multi_class = False, num_class = 2):\n",
    "    val_generator = zip(image_val_generator, mask_val_generator)\n",
    "    for (img_val,mask_val) in val_generator:\n",
    "        img_val,mask_val = adjustData(img_val,mask_val,flag_multi_class,num_class)       \n",
    "        yield (img_val,mask_val)\n",
    "        \n",
    "train_generator = train(image_generator, mask_generator)\n",
    "val_generator = val(image_val_generator, mask_val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Unet(BACKBONE,encoder_weights='imagenet',input_shape=(256,256,3),encoder_freeze=True)\n",
    "model.compile(tf.keras.optimizers.Adam(),loss=sm.losses.bce_jaccard_loss,metrics=['accuracy', mean_iou])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1024 - accuracy: 0.8410 - mean_iou: 0.9474\n",
      "Epoch 00001: val_mean_iou improved from -inf to 0.60981, saving model to pretrained_unet_custom.hdf5\n",
      "100/100 [==============================] - 34s 340ms/step - loss: 0.1024 - accuracy: 0.8410 - mean_iou: 0.9474 - val_loss: 0.8340 - val_accuracy: 0.7743 - val_mean_iou: 0.6098\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1025 - accuracy: 0.8412 - mean_iou: 0.9471\n",
      "Epoch 00002: val_mean_iou improved from 0.60981 to 0.61601, saving model to pretrained_unet_custom.hdf5\n",
      "100/100 [==============================] - 34s 341ms/step - loss: 0.1025 - accuracy: 0.8412 - mean_iou: 0.9471 - val_loss: 0.8313 - val_accuracy: 0.7767 - val_mean_iou: 0.6160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc350c91590>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint = ModelCheckpoint('pretrained_unet_custom.hdf5', monitor='val_mean_iou',verbose=1, save_best_only=True, mode = 'max')\n",
    "model.fit_generator(train_generator,steps_per_epoch=100,epochs=2,validation_data=val_generator,validation_steps=100, callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in model.layers:\n",
    "#     layer.trainable = True\n",
    "# model.compile(tf.keras.optimizers.Adam(1e-6),loss=sm.losses.bce_jaccard_loss,metrics=['accuracy', mean_iou])\n",
    "# model.fit_generator(train_generator,steps_per_epoch=500,epochs=10,validation_data=val_generator,validation_steps=100, callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 256, 256, 3)\n",
      "(4, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "test_img, _= test('dataset/test_images')\n",
    "print(test_img.shape)\n",
    "\n",
    "folder = './dataset/test_labels'\n",
    "num_img, size = test_img.shape[0], test_img.shape[1]\n",
    "\n",
    "\n",
    "def generate_labels(folder, num_img, size, predict):\n",
    "    i=0\n",
    "    test_label = np.zeros((num_img, size,size,1))\n",
    "    for files in os.listdir(folder):\n",
    "        if predict:\n",
    "            if files.startswith(\"custom\"):\n",
    "                mask=load_img(os.path.join(folder,files),target_size=(size,size), color_mode=\"grayscale\")\n",
    "                mask=img_to_array(mask)\n",
    "                if(np.max(mask) > 1):\n",
    "                    mask = mask /255\n",
    "                mask[mask > 0.5] = 1\n",
    "                mask[mask <= 0.5] = 0\n",
    "                test_label[i,:,:,:] = mask\n",
    "                i+=1\n",
    "        else:\n",
    "            if not files.startswith(\"custom\"):\n",
    "                mask=load_img(os.path.join(folder,files),target_size=(size,size), color_mode=\"grayscale\")\n",
    "                mask=img_to_array(mask)\n",
    "                if(np.max(mask) > 1):\n",
    "                    mask = mask /255\n",
    "                mask[mask > 0.5] = 1\n",
    "                mask[mask <= 0.5] = 0\n",
    "                test_label[i,:,:,:] = mask\n",
    "                i+=1\n",
    "    return test_label\n",
    "\n",
    "test_label = generate_labels(folder, num_img, size, False)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 3.0581 - accuracy: 0.7702 - mean_iou: 0.6325\n",
      "Test score: 3.0580530166625977\n"
     ]
    }
   ],
   "source": [
    "model = load_model('pretrained_unet_custom.hdf5', compile = False)\n",
    "model.compile(tf.keras.optimizers.Adam(1e-6),loss=sm.losses.bce_jaccard_loss,metrics=['accuracy', mean_iou])\n",
    "\n",
    "score, accuracy, mean_iou= model.evaluate(test_img, test_label)\n",
    "print('Test score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test2(test_path,target_size=(256,256)):\n",
    "#     X_test=[]\n",
    "#     names=[]\n",
    "#     for filename in os.listdir(test_path):\n",
    "#         name, ext = os.path.splitext(filename)\n",
    "#         if ext!=\".png\" and ext!=\".jpg\":\n",
    "#             continue\n",
    "#         names.append(filename)\n",
    "#         img=load_img(os.path.join(test_path,filename),target_size=target_size)\n",
    "#         img=img_to_array(img)/255\n",
    "#         X_test.append(img.copy())\n",
    "#     return np.array(X_test),names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### TO DO ####\n",
    "# import os\n",
    "\n",
    "# #model=satellite_unet(pretrained='sat_unet_new.hdf5')\n",
    "# X_test,names=test2(\"dataset/test_images\")\n",
    "# preds=model.predict(X_test)\n",
    "# preds=preds>0.5\n",
    "# results=predToImgs(preds)\n",
    "# saveResults(os.getcwd()+\"/dataset/generator_images\",results,names,empty_dir=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "metadata": {
   "deletable": true,
   "editable": true,
   "trusted": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
