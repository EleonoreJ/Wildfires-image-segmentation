{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2MSI_20191226_S2-10.png': 0, '2MSI_20191226_S2-11.png': 0, '2MSI_20191226_S2-3.png': 0, '2MSI_20191226_S2-4.png': 0, '2MSI_20191226_S2-9.png': 1, '2MSI_20200110_S2.png': 1, '2MSI_20200130_S2-2.png': 1, '2MSI_20200130_S2-3.png': 1, '2MSI_20200130_S2-4.png': 1, '2MSI_20200130_S2-5.png': 1, '2MSI_20200130_S2.png': 1, '2MSI_20200224_S2-2.png': 1, '2MSI_20200224_S2.png': 1, '2MSI_20200315_S2.png': 1, '2MSI_20200320_S2-2.png': 1, '2MSI_20200320_S2-3.png': 1, '2MSI_20200320_S2.png': 1, 'MSI_20191214_S2.png': 1, 'MSI_20191216_S2-2.png': 0, 'MSI_20191216_S2.png': 0, 'MSI_20191219_S2.png': 1, 'MSI_20191221_S2-2.png': 0, 'MSI_20191221_S2.png': 1, 'MSI_20191224_S2.png': 1, 'MSI_20191226_S2-2.png': 1, 'MSI_20191226_S2.png': 1, 'MSI_20191227_S2.png': 1, 'MSI_20191228_S2.png': 1, 'MSI_20191229_S2.png': 1, 'MSI_20191231_S2.png': 1, 'MSI_20200108_S2.png': 1, 'MSI_20200126_S2.png': 1, 'MSI_20200129_S2.png': 0, 'MSI_20200130_S2.png': 1, 'MSI_20200202_S2.png': 1}\n"
     ]
    }
   ],
   "source": [
    "## Labels ##\n",
    "dic_labels = {}\n",
    "\n",
    "files = open('dataset/labels_satellite/labels_classifier.txt')\n",
    "lines = files.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    name, label = line.split(' ')\n",
    "    name = name.rstrip('.jpg')\n",
    "    label = int(label.rstrip('\\n'))\n",
    "    dic_labels[name + '.png'] = label\n",
    "print(dic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with 27 images\n",
      "Image examples:\n",
      "2MSI_20200110_S2.png\n",
      "dataset/images_satellite/2MSI_20200110_S2.png\n",
      "27\n",
      "(27, 300, 300, 3)\n",
      "(8, 300, 300, 3)\n"
     ]
    }
   ],
   "source": [
    "## Data ## \n",
    "\n",
    "# folder = 'dataset/images_satellite'\n",
    "\n",
    "onlyfiles = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "\n",
    "print(\"Working with {0} images\".format(len(onlyfiles)))\n",
    "print(\"Image examples:\")\n",
    "\n",
    "# Print one of the examples\n",
    "print(onlyfiles[0])\n",
    "file_path = folder +\"/\" + onlyfiles[0]\n",
    "print(file_path)\n",
    "print(len(onlyfiles))\n",
    "\n",
    "def preprocess(file_path):\n",
    "    img = image.load_img(file_path)\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    return x\n",
    "\n",
    "def image_preprocess(folder):\n",
    "    onlyfiles = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "    target_height = 300\n",
    "    target_width = 300\n",
    "    inputs = np.zeros((len(onlyfiles), target_height, target_width, 3))\n",
    "    \n",
    "    for i in range(0, len(onlyfiles)):\n",
    "        file_path = folder + \"/\" + onlyfiles[i]\n",
    "        img = preprocess(file_path)\n",
    "        inputs[i,:,:,:] = img\n",
    "    return inputs,  len(onlyfiles)\n",
    "\n",
    "\n",
    "inputs_pos, shape = image_preprocess('dataset/images_satellite')\n",
    "inputs_neg, shape_neg = image_preprocess('dataset/images_unburnt')\n",
    "print(inputs_pos.shape)\n",
    "print(inputs_neg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# cd dataset\n",
    "# mkdir images_unburnt_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True)\n",
    "\n",
    "i = 0\n",
    "for batch in datagen.flow(inputs_neg, batch_size=1,\n",
    "                          save_to_dir='dataset/images_unburnt_augmented', save_format='jpg'):\n",
    "    i += 1\n",
    "    if i > 15:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 300, 300, 3)\n",
      "(46, 300, 300, 3)\n",
      "(76, 300, 300, 3)\n",
      "(30,)\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "inputs_pos, shape = image_preprocess('dataset/images_augmented')\n",
    "inputs_neg, shape_neg = image_preprocess('dataset/images_unburnt_augmented')\n",
    "print(inputs_pos.shape)\n",
    "print(inputs_neg.shape)\n",
    "\n",
    "inputs = np.concatenate((inputs_pos,inputs_neg), axis=0)\n",
    "print(inputs.shape)\n",
    "      \n",
    "labels = np.zeros(inputs.shape[0])\n",
    "labels[:shape] = 1\n",
    "print(labels[:shape].shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76 samples\n",
      "Epoch 1/5\n",
      "76/76 [==============================] - 5s 72ms/sample - loss: 5.6763 - accuracy: 0.4605\n",
      "Epoch 2/5\n",
      "76/76 [==============================] - 0s 6ms/sample - loss: 0.3990 - accuracy: 0.7763\n",
      "Epoch 3/5\n",
      "76/76 [==============================] - 0s 6ms/sample - loss: 0.1165 - accuracy: 0.9605\n",
      "Epoch 4/5\n",
      "76/76 [==============================] - 0s 5ms/sample - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "76/76 [==============================] - 0s 5ms/sample - loss: 0.0026 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 2 classes\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# for i, layer in enumerate(base_model.layers):\n",
    "#    print(i, layer.name)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "history = model.fit(inputs,labels,batch_size=50, epochs=5, verbose=1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 300, 300, 3)\n",
      "[[1.00000000e+00 6.91618336e-16]\n",
      " [1.00000000e+00 1.23658865e-30]\n",
      " [1.00000000e+00 4.12014626e-17]\n",
      " [9.97558951e-01 2.44100066e-03]]\n"
     ]
    }
   ],
   "source": [
    "img_test, _ = image_preprocess('dataset/test_images')\n",
    "print(img_test.shape)\n",
    "prediction = model.predict(img_test)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
